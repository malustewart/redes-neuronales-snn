% Encoding: UTF-8
 @article{Hendy_Merkel_2022,
  title        = {Review of spike-based neuromorphic computing for brain-inspired vision: biology, algorithms, and hardware},
  volume       = {31},
  issn         = {1017-9909, 1560-229X},
  doi          = {10.1117/1.JEI.31.1.010901},
  abstractnote = {Neuromorphic computing is becoming a popular approach for implementations of brain-inspired machine learning tasks. As a paradigm for both hardware and algorithm design, neuromorphic computing aims to emulate several aspects related to the structure and function of the biological nervous system to achieve artificial intelligence with efficiencies that are orders of magnitude better than those exhibited by general-purpose computing hardware. We provide a holistic treatment of spike-based neuromorphic computing (i.e., based on spiking neural networks), detailing biological motivation, key aspects of neuromorphic algorithms, and a survey of state-of-the-art neuromorphic hardware. In particular, we focus on these aspects within the context of brain-inspired vision applications. Our aim is to serve as a complement to several of the existing reviews on neuromorphic computing while also providing a unique perspective.},
  number       = {1},
  journal      = {Journal of Electronic Imaging},
  publisher    = {SPIE},
  author       = {Hendy, Hagar and Merkel, Cory},
  year         = {2022},
  month        = jan,
  pages        = {010901}
}

 @article{snntorch_2023,
  title        = {Training Spiking Neural Networks Using Lessons From Deep Learning},
  url          = {http://arxiv.org/abs/2109.12894},
  doi          = {10.48550/arXiv.2109.12894},
  abstractnote = {The brain is the perfect place to look for inspiration to develop more efficient neural networks. The inner workings of our synapses and neurons provide a glimpse at what the future of deep learning might look like. This paper serves as a tutorial and perspective showing how to apply the lessons learnt from several decades of research in deep learning, gradient descent, backpropagation and neuroscience to biologically plausible spiking neural neural networks. We also explore the delicate interplay between encoding data as spikes and the learning process; the challenges and solutions of applying gradient-based learning to spiking neural networks (SNNs); the subtle link between temporal backpropagation and spike timing dependent plasticity, and how deep learning might move towards biologically plausible online learning. Some ideas are well accepted and commonly used amongst the neuromorphic engineering community, while others are presented or justified for the first time here. The fields of deep learning and spiking neural networks evolve very rapidly. We endeavour to treat this document as a “dynamic” manuscript that will continue to be updated as the common practices in training SNNs also change. A series of companion interactive tutorials complementary to this paper using our Python package, snnTorch, are also made available. See https://snntorch.readthedocs.io/en/latest/tutorials/index.html .},
  note         = {arXiv:2109.12894 [cs]},
  number       = {arXiv:2109.12894},
  publisher    = {arXiv},
  author       = {Eshraghian, Jason K. and Ward, Max and Neftci, Emre and Wang, Xinxin and Lenz, Gregor and Dwivedi, Girish and Bennamoun, Mohammed and Jeong, Doo Seok and Lu, Wei D.},
  year         = {2023},
  month        = aug
}

 @article{Maass_1997,
  title        = {Networks of spiking neurons: The third generation of neural network models},
  volume       = {10},
  rights       = {https://www.elsevier.com/tdm/userlicense/1.0/},
  issn         = {08936080},
  doi          = {10.1016/S0893-6080(97)00011-7},
  abstractnote = {The computational power of formal models for networks of spiking neurons is compared with that of other neural network models based on McCulloch Pitts neurons (i.e., threshold gates), respectively, sigmoidal gates. In particular it is shown that networks of spiking neurons are, with regard to the number of neurons that are needed, computationally more powerful than these other neural network models. A concrete biologically relevant function is exhibited which can be computed by a single spiking neuron (for biologically reasonable values of its parameters), but which requires hundreds of hidden units on a sigmoidal neural net. On the other hand, it is known that any function that can be computed by a small sigmoidal neural net can also be computed by a small network of spiking neurons. This article does not assume prior knowledge about spiking neurons, and it contains an extensive list of references to the currently available literature on computations in networks of spiking neurons and relevant results from neurobiology. © 1997 Elsevier Science Ltd. All rights reserved.},
  number       = {9},
  journal      = {Neural Networks},
  author       = {Maass, Wolfgang},
  year         = {1997},
  month        = dec,
  pages        = {1659–1671},
  language     = {en}
}

@inproceedings{gesture_recognition_2017,
  title        = {A Low Power, Fully Event-Based Gesture Recognition System},
  issn         = {1063-6919},
  url          = {https://ieeexplore.ieee.org/document/8100264/},
  doi          = {10.1109/CVPR.2017.781},
  abstractnote = {We present the first gesture recognition system implemented end-to-end on event-based hardware, using a TrueNorth neurosynaptic processor to recognize hand gestures in real-time at low power from events streamed live by a Dynamic Vision Sensor (DVS). The biologically inspired DVS transmits data only when a pixel detects a change, unlike traditional frame-based cameras which sample every pixel at a fixed frame rate. This sparse, asynchronous data representation lets event-based cameras operate at much lower power than frame-based cameras. However, much of the energy efficiency is lost if, as in previous work, the event stream is interpreted by conventional synchronous processors. Here, for the first time, we process a live DVS event stream using TrueNorth, a natively event-based processor with 1 million spiking neurons. Configured here as a convolutional neural network (CNN), the TrueNorth chip identifies the onset of a gesture with a latency of 105 ms while consuming less than 200 mW. The CNN achieves 96.5% out-of-sample accuracy on a newly collected DVS dataset (DvsGesture) comprising 11 hand gesture categories from 29 subjects under 3 illumination conditions.},
  booktitle    = {2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  author       = {Amir, Arnon and Taba, Brian and Berg, David and Melano, Timothy and McKinstry, Jeffrey and Di Nolfo, Carmelo and Nayak, Tapan and Andreopoulos, Alexander and Garreau, Guillaume and Mendoza, Marcela and Kusnitz, Jeff and Debole, Michael and Esser, Steve and Delbruck, Tobi and Flickner, Myron and Modha, Dharmendra},
  year         = {2017},
  month        = jul,
  pages        = {7388–7397}
}